{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knn From Scratch:\n",
    "\n",
    "The goal of this exercise to implement the knn algorithm from scratch for both regression and classification problem.\n",
    "In addition to this, the cross validation and nested cross validation are also implemented from scratch and compare them with the built in scikit-learn libary. Thus, knn_class is defined. For classification problem, method- knn_classifer_prediction() should be called and for regression problem, method- knn_regression_prediction() should be called. The algorithm is implemented as following steps-wise:\n",
    "\n",
    "   1.Find the distance(Eculidan is used) between two data points(instances)\n",
    "\n",
    "   2.Sort the distance. Take the 'first k most closest neighbours' of the test instance in the training data set.\n",
    "      \n",
    "   For classification: Find the most frequent neighbour from the  'k most closet neighbours'  and labels that test instance to that neighbour(class) \n",
    "        \n",
    "   For Regression:  Find the average of  target varaibles of the 'k most closest neigbours' and used as predicted value for that test instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import randrange\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Knn class\n",
    "class knn_class:\n",
    "    \n",
    "    \"\"\" Both classification and regression problem are solved with this code.\"\"\"\n",
    "    \n",
    "    # calculates eculidan distance between two data instances\n",
    "    def eculidan_dist(self, data1, data2, length):\n",
    "        distance = 0\n",
    "        # loop through all variables\n",
    "        for x in range(length):\n",
    "            distance += np.power((data1[x]- data2[x]),2)\n",
    "        return np.sqrt(distance)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # finds k nearest  neighbors  to test instance using the ecludian distance \n",
    "    def get_neighbours(self, trainingSet, testInstance, k):\n",
    "        distance = []\n",
    "        length =  len(testInstance) -1 # all variables except target variable\n",
    "        \n",
    "        # find distance  between test instance to all training instances\n",
    "        for x in range(len(trainingSet)):\n",
    "            dist =  self.eculidan_dist(trainingSet[x], testInstance, length) # call eculidan_dist function\n",
    "            distance.append((trainingSet[x], dist)) \n",
    "        \n",
    "        # sort the distance in ascending order\n",
    "        distance.sort(key=operator.itemgetter(1))\n",
    "        #print(distance)\n",
    "    \n",
    "        #store the  k neighbours\n",
    "        neighbours = []\n",
    "        for x in  range(k):\n",
    "            neighbours.append(distance[x][0])\n",
    "        return neighbours\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\" ======== For classification problem, start from here ======= \"\"\"\n",
    "    # finds class that test instance belongs to. This is done by finding the  the most frequent class in the k neigbours\n",
    "    def get_response(self, neighbors):\n",
    "        classVotes = {}\n",
    "        for x in range(len(neighbors)):\n",
    "            response = neighbors[x][-1] # take last attribute(target variable) \n",
    "            if response in classVotes:\n",
    "                classVotes[response] +=1\n",
    "            \n",
    "            else:\n",
    "                classVotes[response] = 1\n",
    "    \n",
    "        # sorts classes with higest values\n",
    "        sortedVotes = sorted(classVotes.items(),key=operator.itemgetter(1), reverse=True) #sorting based on max count\n",
    "        return  sortedVotes[0][0] # take first neighbour\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # generates prediction for the given test set data\n",
    "    def knn_classifer_prediction(self, testSet, trainingSet,  k):\n",
    "        predictions = []\n",
    "        actual = []\n",
    "        for x in range(len(testSet)):\n",
    "            neighbors = self.get_neighbours(trainingSet, testSet[x], k )\n",
    "            response = self.get_response(neighbors)\n",
    "            predictions.append(response)\n",
    "            actual.append(testSet[x][-1])\n",
    "        return predictions, actual\n",
    "        \n",
    "\n",
    "    # find the prediction accuracy\n",
    "    def get_accuracy(self, testSet, predictions):\n",
    "        correct = 0.0\n",
    "        \n",
    "        #compare the testSet target varibles with the prediction class\n",
    "        # and count the correct number of predictions\n",
    "        for x in range(len(testSet)):\n",
    "            if testSet[x][-1] is predictions[x]:\n",
    "                correct +=1\n",
    "        \n",
    "        return correct/ float(len(testSet))\n",
    "        \n",
    "  \n",
    "\n",
    "    \"\"\"============ For Regression problem start from here ===============\"\"\"      \n",
    "          \n",
    "    # finds average of the k neighbors target variables\n",
    "    def get_average(self, neighbors):\n",
    "        ave_value = 0\n",
    "        total_neig = len(neighbors)\n",
    "        for x in range(total_neig):\n",
    "            ave_value += neighbors[x][-1] # take last attributes (target varibales)\n",
    "        return round(ave_value/total_neig, 2) # average the values\n",
    "    \n",
    "    \n",
    "    \n",
    "    # generates prediction of the given testset\n",
    "    def knn_regression_prediction(self, testSet, trainingSet,  k):\n",
    "        predictions = []\n",
    "        for x in range(len(testSet)):\n",
    "            neighbors = self.get_neighbours(trainingSet, testSet[x], k ) # call get_neighbours function\n",
    "            print(neighbors)\n",
    "            predict_val = self.get_average(neighbors) # call get_average function\n",
    "            predictions.append(predict_val) # sum the value\n",
    "        return predictions\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset:\n",
    "The iris flower dataset is used  for the classfication  problem. It consists of 150 data instances of three class each \n",
    "of 50 instances. The dataset has  4 predicted attributes and the class. In the dataset, the labels/classes are placed in order form, which means that there no randomization of the class. Thus, the data need to shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>Flower_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      Flower_Name\n",
       "0           6.0          2.7           5.1          1.6  Iris-versicolor\n",
       "1           5.5          3.5           1.3          0.2      Iris-setosa\n",
       "2           5.1          2.5           3.0          1.1  Iris-versicolor\n",
       "3           5.6          2.5           3.9          1.1  Iris-versicolor\n",
       "4           6.3          3.4           5.6          2.4   Iris-virginica"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load  iris dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_name = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width','Flower_Name']\n",
    "df = pd.read_csv(url, header=None, delimiter=',', names=col_name)\n",
    "iris_df = df.sample(frac=1).reset_index(drop=True) # shuffle the data and reset index\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#provides the statistical descriptive \n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spilt data into train set and test set\n",
    "def train_test_split(data_set, split_ratio):\n",
    "    trainingSet = []\n",
    "    testSet = []\n",
    "    \n",
    "    for x in range(len(data_set)):\n",
    "        if random.random() < split_ratio:\n",
    "            trainingSet.append(data_set[x])\n",
    "        else:\n",
    "            testSet.append(data_set[x])\n",
    "    return trainingSet, testSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size:  44  and Train size:  106\n"
     ]
    }
   ],
   "source": [
    "#call the train_test_split function\n",
    "data_set = iris_df.values.tolist() # convert to python list \n",
    "split_ratio = 0.70\n",
    "#random.seed(30) # split into  same data every time code is executed \n",
    "train_set, test_set = train_test_split(data_set, split_ratio)\n",
    "print('Test size: ',len(test_set), ' and Train size: ', len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed class and predicted class:\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-virginica ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-virginica ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-virginica ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-setosa ,    Actual = Iris-setosa\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-virginica ,    Actual = Iris-virginica\n",
      " Predicted = Iris-versicolor ,    Actual = Iris-versicolor\n",
      "\n",
      "Accuracy is 0.93\n"
     ]
    }
   ],
   "source": [
    "#check the classification problem \n",
    "\n",
    "knn_object =  knn_class()\n",
    "k = 5\n",
    "predict, actual = knn_object.knn_classifer_prediction(test_set, train_set, k) #call knn classification method\n",
    "\n",
    "#Observed class and predicted class\n",
    "print('Observed class and predicted class:')\n",
    "for x in range(len(predict)):\n",
    "    print(' Predicted =', predict[x], ',    Actual =',  actual[x])\n",
    "\n",
    "#find accuracy\n",
    "accu_score = knn_object.get_accuracy(test_set, predict)\n",
    "print('\\nAccuracy is {0:.2f}'.format(accu_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.4, 2, 1, 4, 6], [2, 2.5, 3, 1, 4], [5, 2, 3, 4, 7]]\n",
      "preditected value is:  [5.67]\n"
     ]
    }
   ],
   "source": [
    "#check for regression problem\n",
    "knn_object =  knn_class()\n",
    "k=3\n",
    "test= [[1,2,3,4,2]]\n",
    "train= [[3.4,2,1,4,6], [5,2,1,4,5], [2,2.5,3,1,4], [5,2,3,4,7]]\n",
    "predict = knn_class().knn_regression_prediction(test, train, k) # call regresion method\n",
    "\n",
    "print('preditected value is: ', predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                       ====== Cross Validation =========\n",
    "The two functions are used for Cross Validation i.e 1) cross_validation_split() and 2) cross_validation() . The first function divides the dataset into 'n_folds' and the second function is used to  evaluate the model performance.  For separating the test and train dataset, the python list indexing is used.          \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data for cross validation\n",
    "def cross_validation_split(dataset, folds):\n",
    "    fold_size = int(len(dataset)/folds) # size  of each fold\n",
    "    #print(fold_size)\n",
    "    dataset_split =  []\n",
    "    dataset_copy = dataset.copy() #duplicate the dataset, so that it is used for generating index later \n",
    "    \n",
    "    \n",
    "    #assign data instance to each folds\n",
    "    for x in range(folds):\n",
    "        each_fold_data = []\n",
    "        while len(each_fold_data) < fold_size:\n",
    "            index = randrange(0,len(dataset_copy)) # generate random number from 0 to size of dataset\n",
    "            each_fold_data.append(dataset_copy.pop(index)) # append  each popped data to each fold\n",
    "        dataset_split.append(each_fold_data) # append each fold to data_split\n",
    "        \n",
    "        \n",
    "    #check if the items are remain in list (dataset_copy) and assign to the last fold\n",
    "    if dataset_copy:\n",
    "        for x in range(len(dataset_copy)):\n",
    "            dataset_split[-1].append(dataset_copy[x])\n",
    "       #dataset_split[-1].extend(dataset_copy)\n",
    "    #print(dataset_copy)\n",
    "    \n",
    "    return dataset_split\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation  Method\n",
    "import random\n",
    "def cross_validation(dataset, n_folds, k):\n",
    "    random.seed(2)\n",
    "    data_split = cross_validation_split(dataset,n_folds) # call cross_validation_split function\n",
    "    accu_cross_val = []\n",
    "    \n",
    "    #take single fold as test data and remaisnig(n-1) as train data (list indexing is used)\n",
    "    for index, item  in enumerate(data_split):\n",
    "        test = data_split[index] # for test data\n",
    "        train = data_split[0:index]+ data_split[index+1:] # for train data\n",
    "        train = [instance for item in train for instance in item ] # change 3d into 2d list\n",
    "            \n",
    "        prediction, actual = knn_object.knn_classifer_prediction(test, train, k) #gives prediction and actual class\n",
    "        accuracy = knn_object.get_accuracy(test, prediction) #find the accuracy\n",
    "        #print(accuracy)\n",
    "        accu_cross_val.append(accuracy)\n",
    "        #print(accuracy,\\n')\n",
    "        \n",
    "        \n",
    "    #average the score from n_folds\n",
    "    score = np.mean(accu_cross_val) \n",
    "    return round(score,2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check  cross_validation\n",
    "cross_validation(train_set,10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optmal_k is 9 and high_score is 0.98\n"
     ]
    }
   ],
   "source": [
    "# find optimal k for knn using 10-fold cross validation\n",
    "optimal_k = 0\n",
    "high_score = 0\n",
    "     \n",
    "#iterates over number of k in KNN    \n",
    "for k in range(1,20):\n",
    "    score_cv =  cross_validation(train_set,10, k) #call crossvalidation function\n",
    "    #print('{0:.2f}'.format(score_cv))\n",
    "    \n",
    "    #check k of high score\n",
    "    if score_cv > high_score:\n",
    "        high_score = score_cv\n",
    "        optimal_k = k\n",
    "    \n",
    "print('Optmal_k is {0} and high_score is {1:.2f}'.format(optimal_k, high_score)) \n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        ========= Nested Cross Validation ===========\n",
    "Nested Cross Validation has two cross valdiation loops i.e outer and inner loop. Outer loop is used for model perfomance evaluation whereas inner loop is used for finding/tunning the model optimal parameter, for example, \n",
    "k in Knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define nested cross validation function\n",
    "import random\n",
    "def nested_crossValidation(dataset, n_folds):\n",
    "    random.seed(32)\n",
    "    \n",
    "    #split the dataset into n_folds\n",
    "    data_split = cross_validation_split(dataset, n_folds)  #call split function\n",
    "    predictin_accuracy = []\n",
    "    \n",
    "    ''' Outer CV start here'''\n",
    "    #outer loop use for model performance evaluation\n",
    "    for index, item in enumerate(data_split):\n",
    "        test = data_split[index] # for test data\n",
    "        train = data_split[0:index]+ data_split[index+1:] # for train data\n",
    "        train = [instance for item in train for instance in item ] # change 3d into 2d list\n",
    "        \n",
    "        \n",
    "        \n",
    "        high_score = 0\n",
    "        optimal_k = 0\n",
    "        \n",
    "        #find the optimal value of k\n",
    "        for k in range(1,20):\n",
    "            accu_inner_cross = [] # stores accuracy of test fold of inner CV\n",
    "            \n",
    "            \n",
    "            '''Inner CV start here, train set of Outer CV is used as data set in inner CV'''\n",
    "            \n",
    "            # train data of outer CV  splits into futher folds\n",
    "            data_split_1 = cross_validation_split(train, n_folds) \n",
    "            \n",
    "            #inner loop user for finding the optimal k in KNN\n",
    "            for index, item in enumerate(data_split_1):\n",
    "                test_1 = data_split_1[index] # for test data\n",
    "                train_1 = data_split_1[0:index]+ data_split_1[index+1:] # for train data\n",
    "                train_1 = [instance for item in train_1 for instance in item ] # change 3d into 2d list\n",
    "            \n",
    "                prediction, actual = knn_object.knn_classifer_prediction(test_1, train_1, k ) # call knn_classifer_prediction method\n",
    "                accuracy = knn_object.get_accuracy(test_1, prediction) # call get_accuracy method\n",
    "                accu_inner_cross.append(accuracy)\n",
    "           \n",
    "            score =  np.mean(accu_inner_cross)\n",
    "            #print(score)\n",
    "            \n",
    "            #check for optimal k of high score \n",
    "            if score > high_score:\n",
    "                high_score= score\n",
    "                optimal_k =k\n",
    "        \n",
    "\n",
    "        print('Optimal_k is:',optimal_k)\n",
    "        \n",
    "        #use the optimal k and evaluate the model prediction\n",
    "        prediction, actual = knn_object.knn_classifer_prediction(test, train, optimal_k )\n",
    "        accuracy = knn_object.get_accuracy(test, prediction)\n",
    "        predictin_accuracy.append(accuracy)\n",
    "        \n",
    "    return  round(np.mean(predictin_accuracy),2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal_k is: 7\n",
      "Optimal_k is: 14\n",
      "Optimal_k is: 12\n",
      "Optimal_k is: 11\n",
      "Optimal_k is: 10\n",
      "Optimal_k is: 8\n",
      "Optimal_k is: 9\n",
      "Optimal_k is: 12\n",
      "Optimal_k is: 9\n",
      "Optimal_k is: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check nested cross validation\n",
    "n_folds = 10\n",
    "dataset = train_set\n",
    "nested_crossValidation(dataset, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "               ========= Comparing with scikitlearn library ============\n",
    "               \n",
    "To compare implemented knn  classifer with the scikitlearn Knn classifer, the same  training and testing dataset \n",
    "should be in both. Already in the knn scratch implementation, the data is python list form. So it should convert \n",
    "into pandas dataframe  because it is more convient to seprate  from panda dataframe into  input features and  target \n",
    "class. The reason doing this is the knn algorithm in scikitlearn uses separate input features and target lables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import  cross_val_score, KFold\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (112, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>Flower_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sepal_length sepal_width petal_length petal_width      Flower_Name\n",
       "0          5.0         3.5          1.6         0.6      Iris-setosa\n",
       "1          5.7         4.4          1.5         0.4      Iris-setosa\n",
       "2          5.5         2.4          3.8         1.1  Iris-versicolor\n",
       "3          7.7         3.8          6.7         2.2   Iris-virginica\n",
       "4          5.5         2.6          4.4         1.2  Iris-versicolor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the data into pandas data frame\n",
    "\n",
    "train = pd.DataFrame(np.array(train_set), columns=iris_df.columns)\n",
    "# train.iloc[:,0:4] = train.iloc[:,0:4].apply(pd.to_numeric)\n",
    "test = pd.DataFrame(np.array(test_set), columns=iris_df.columns)\n",
    "# test.iloc[:,0:4] = train.iloc[:,0:4].apply(pd.to_numeric)\n",
    "print('train size:', train.shape)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: (38, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>Flower_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sepal_length sepal_width petal_length petal_width      Flower_Name\n",
       "0          6.5         3.2          5.1         2.0   Iris-virginica\n",
       "1          6.2         2.2          4.5         1.5  Iris-versicolor\n",
       "2          6.0         3.4          4.5         1.6  Iris-versicolor\n",
       "3          4.9         3.1          1.5         0.1      Iris-setosa\n",
       "4          5.6         3.0          4.1         1.3  Iris-versicolor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('test size:', test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define knn classifer\n",
    "def knn_function(x_train, y_train, x_test, y_test, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k) # initiate knn classier\n",
    "    knn.fit(x_train,y_train) # train with data\n",
    "    prediction = knn.predict(x_test) # get prediction\n",
    "    print('Prediction: \\n {}'.format(prediction))\n",
    "    #a = knn.score(x_test,y_test)\n",
    "    #print(a)\n",
    "    accu_score= metrics.accuracy_score(y_test, prediction)\n",
    "    return accu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      " ['Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor']\n",
      "\n",
      " Accuracy is: 0.95\n"
     ]
    }
   ],
   "source": [
    "# split data into input features and target class\n",
    "x_train, y_train = train.iloc[:,0:4], train.iloc[:,-1]\n",
    "x_test, y_test = test.iloc[:,0:4], test.iloc[:,-1]\n",
    "\n",
    "k= 5 #since we use k= 5 in knn scratch\n",
    "\n",
    "accu_score = knn_function(x_train, y_train, x_test, y_test, k) # call knn_function \n",
    "print('\\n Accuracy is: {0:.2f}'.format(accu_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation score is 0.97\n"
     ]
    }
   ],
   "source": [
    "#Cross validation using KFolds\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "kflod = KFold(n_splits=10)\n",
    "x_train, y_train = train.iloc[:,0:4], train.iloc[:,-1] # separates input features and target variable\n",
    "score = cross_val_score(knn, x_train, y_train, cv=kflod, scoring='accuracy')\n",
    "print('Cross Validation score is {0:.2f}'.format(score.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_k is: 8\n",
      "optimal_k is: 10\n",
      "optimal_k is: 5\n",
      "optimal_k is: 18\n",
      "optimal_k is: 3\n",
      "optimal_k is: 16\n",
      "optimal_k is: 16\n",
      "optimal_k is: 3\n",
      "optimal_k is: 3\n",
      "optimal_k is: 3\n",
      "\n",
      "Model accuracy is: 0.95\n"
     ]
    }
   ],
   "source": [
    "#Nested Cross validation\n",
    "\n",
    "kflod = KFold(n_splits=10) #divides data into 10 folds\n",
    "data, target = train.iloc[:,0:4], train.iloc[:,-1] # separates input features and target variable\n",
    "\n",
    "outer_loop_acc = [] # stores accuracy of each folds in outer CV\n",
    "\n",
    "\"\"\"Outer CV start here\"\"\"\n",
    "#Provides train/test indices to split data in train/test sets\n",
    "for  train_index, test_index in kflod.split(data):\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index] \n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    #print(len(X_train), len(X_test))\n",
    "    \n",
    "    \n",
    "    \n",
    "    bestAccuracy =0\n",
    "    optimal_k = 0\n",
    "    \n",
    "    #iterates over k = (1,20) in KNN\n",
    "    for k in range(1,20): \n",
    "        inner_loop_accu = [] # store accuracy  of each fold in inner CV\n",
    "    \n",
    "        \"\"\"Inner CV start here, train set of outer CV is used as dataset in inner CV\"\"\"\n",
    "        \n",
    "        #Provides train/test indices to split data in train/test sets\n",
    "        for  train_index, test_index in kflod.split(X_train):\n",
    "            X_train_inner, X_test_inner = X_train.iloc[train_index], X_train.iloc[test_index] \n",
    "            y_train_inner, y_test_inner = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "            #print(len(X_train_inner),len(X_test_inner))\n",
    "        \n",
    "            knn= KNeighborsClassifier( n_neighbors= k) # create Knn classifer\n",
    "            knn.fit(X_train_inner,y_train_inner) # train the classifier\n",
    "            prediction = knn.predict(X_test_inner) # get response from test data\n",
    "            accuracy = metrics.accuracy_score(y_test_inner, prediction) # calculates accuracy\n",
    "            inner_loop_accu.append(accuracy)\n",
    "        \n",
    "        score = np.mean(inner_loop_accu) # average the\n",
    "        #print('k', k)\n",
    "        #print(score)\n",
    "        \n",
    "        #check best accuracy\n",
    "        if score > bestAccuracy:\n",
    "            bestAccuracy = score\n",
    "            optimal_k = k\n",
    "    \n",
    "    print('optimal_k is: {0}'.format(optimal_k))\n",
    "    \n",
    "    # use optimal k for outer CV \n",
    "    knn= KNeighborsClassifier( n_neighbors= optimal_k) # create Knn classifer\n",
    "    knn.fit(X_train, y_train) # train the classifier\n",
    "    prediction = knn.predict(X_test) # get response from test data\n",
    "    accuracy = metrics.accuracy_score(y_test, prediction) # calculates accuracy\n",
    "    outer_loop_acc.append(accuracy)\n",
    "\n",
    "print('\\nModel accuracy is: {0:.2f}'.format(np.mean(outer_loop_acc)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion: \n",
    "After analysing the results, the implemented Knn classifer works fine as like scikit-learn knn classifer. The cross validation and  nested cross validation work same as scikit-learn. There is almost the same result both in scikit-learn and implemented knn classifer.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
